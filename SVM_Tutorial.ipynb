{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print(os.getcwd())\n",
    "path=\"C:\\\\Users\\\\19802\\\\Documents\\\\nibl\\\\mouse_data\\\\Sucrose_infusions_dataframe_Eric.csv\" # set path to file\n",
    "data=pd.read_csv(path) # read in as dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.get_dummies(data, columns=[\"MouseId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)  \n",
    "\n",
    "* capable of doing linear classification, and other non-linear basis functions.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with categorical values is a common practice in machine learning and other statistical computing areas. Typically stored as a text value, the challenge is determining how to use and represent this data in the analysis. Some algorithms are capable of handling these variables without manipulation, but when that isn't the case we must modify these variables. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma parameter defines how far the influence of a single training example reaches, with low values meaning far and high values meaning close. Gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.   \n",
    "\n",
    "C parameter treades off correct classification of training examples against maximization of the decision function's margin. For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. **A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy.** In other words C behaves as a regularization parameter in the SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
